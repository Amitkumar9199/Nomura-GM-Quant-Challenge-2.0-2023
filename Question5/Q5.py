import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from lightgbm import LGBMClassifier

# extracted from training data
ECO_map = {'A00': 0.5625,'A01': 0.6145833333333334,'A02': 0.6097560975609756,'A03': 0.7,'A04': 0.582010582010582,'A05': 0.5714285714285714,'A06': 0.5,'A07': 0.48314606741573035,'A08': 0.7222222222222222,'A09': 0.4888888888888889,'A10': 0.45454545454545453,'A11': 0.6666666666666666,'A12': 0.5,'A13': 0.47297297297297297,'A14': 0.5,'A15': 0.638095238095238,'A16': 0.4074074074074074,'A17': 0.625,'A18': 0.3333333333333333,'A19': 0.2,'A20': 0.6511627906976745,'A21': 0.6086956521739131,'A22': 0.42857142857142855,'A23': 0.5,'A24': 0.0,'A25': 0.5,'A27': 0.625,'A28': 0.3157894736842105,'A29': 0.6666666666666666,'A30': 0.5652173913043478,'A31': 0.6111111111111112,'A32': 0.5,'A33': 0.7142857142857143,'A34': 0.6666666666666666,'A35': 0.5454545454545454,'A36': 0.2857142857142857,'A37': 0.5384615384615384,'A38': 0.0,'A39': 0.5,'A40': 0.5533980582524272,'A41': 0.5185185185185185,'A42': 0.47058823529411764,'A43': 0.5747126436781609,'A44': 0.5483870967741935,'A45': 0.4823943661971831,'A46': 0.44654088050314467,'A47': 0.5833333333333334,'A48': 0.6588235294117647,'A49': 0.5454545454545454,'A50': 0.5945945945945946,'A51': 0.6,'A52': 0.5,'A53': 0.5217391304347826,'A54': 0.4,'A55': 0.5,'A56': 0.4594594594594595,'A57': 0.6410256410256411,'A58': 0.3125,'A59': 0.7,'A60': 0.6666666666666666,'A61': 0.7777777777777778,'A62': 0.7,'A65': 0.2727272727272727,'A67': 0.2857142857142857,'A68': 0.5,'A69': 0.6666666666666666,'A70': 0.5714285714285714,'A72': 0.0,'A73': 0.0,'A77': 1.0,'A78': 0.0,'A79': 1.0,'A80': 0.5,'A81': 0.8,'A82': 0.0,'A83': 0.3333333333333333,'A84': 0.4444444444444444,'A85': 0.375,'A86': 0.3333333333333333,'A87': 0.3333333333333333,'A88': 0.5,'A89': 0.3333333333333333,'A90': 1.0,'A92': 0.0,'A94': 1.0,'A95': 0.0,'A96': 0.3333333333333333,'A98': 0.0,'A99': 1.0,'B00': 0.48863636363636365,'B01': 0.524390243902439,'B02': 0.5142857142857142,'B03': 0.4358974358974359,'B04': 0.47368421052631576,'B05': 0.23076923076923078,'B06': 0.47474747474747475,'B07': 0.5470085470085471,'B08': 0.41379310344827586,'B09': 0.5833333333333334,'B10': 0.5,'B11': 0.4166666666666667,'B12': 0.5555555555555556,'B13': 0.625,'B14': 0.5652173913043478,'B15': 0.5280898876404494,'B16': 0.0,'B17': 0.47058823529411764,'B18': 0.631578947368421,'B19': 0.5555555555555556,'B20': 0.5176470588235295,'B21': 0.5348837209302325,'B22': 0.5714285714285714,'B23': 0.5380116959064327,'B24': 0.5882352941176471,'B25': 0.5,'B26': 0.5,'B27': 0.48214285714285715,'B28': 0.44,'B29': 0.2222222222222222,'B30': 0.5,'B31': 0.6060606060606061,'B32': 0.5128205128205128,'B33': 0.4642857142857143,'B34': 0.4,'B35': 0.5294117647058824,'B36': 0.5,'B37': 0.5,'B38': 0.55,'B39': 0.16666666666666666,'B40': 0.4827586206896552,'B41': 0.5294117647058824,'B42': 0.5652173913043478,'B43': 0.22580645161290322,'B44': 0.5833333333333334,'B46': 0.6,'B47': 0.4444444444444444,'B48': 0.6666666666666666,'B49': 1.0,'B50': 0.4318181818181818,'B51': 0.5135135135135135,'B52': 0.5102040816326531,'B53': 0.5555555555555556,'B54': 0.6086956521739131,'B55': 1.0,'B56': 0.48,'B57': 0.5,'B58': 1.0,'B59': 0.0,'B60': 0.6,'B61': 0.3333333333333333,'B62': 0.5714285714285714,'B63': 0.25,'B64': 0.0,'B65': 0.0,'B66': 0.5,'B67': 0.25,'B68': 1.0,'B69': 1.0,'B70': 0.5625,'B71': 0.6,'B72': 0.25,'B74': 1.0,'B75': 0.3333333333333333,'B76': 0.48,'B77': 0.75,'B78': 0.625,'B80': 0.6666666666666666,'B81': 0.6,'B82': 1.0,'B84': 0.7142857142857143,'B85': 0.3333333333333333,'B87': 0.3333333333333333,'B88': 1.0,'B89': 0.3333333333333333,'B90': 0.5764705882352941,'B91': 0.0,'B92': 0.6923076923076923,'B93': 0.5,'B94': 0.4166666666666667,'B95': 0.5,'B96': 0.45454545454545453,'B97': 0.3333333333333333,'B98': 0.0,'B99': 0.8,'C00': 0.503030303030303,'C01': 0.5208333333333334,'C02': 0.5729166666666666,'C03': 0.3333333333333333,'C04': 0.4,'C05': 0.6153846153846154,'C06': 0.6153846153846154,'C07': 0.5263157894736842,'C08': 0.0,'C09': 0.5,'C10': 0.5517241379310345,'C11': 0.47761194029850745,'C12': 0.5,'C13': 0.4166666666666667,'C14': 0.8571428571428571,'C15': 0.5555555555555556,'C16': 0.3888888888888889,'C17': 0.42857142857142855,'C18': 0.5454545454545454,'C19': 0.6206896551724138,'C20': 0.6666666666666666,'C21': 0.2857142857142857,'C22': 0.5,'C23': 0.75,'C24': 0.4375,'C25': 0.46153846153846156,'C26': 0.5652173913043478,'C27': 1.0,'C28': 0.3333333333333333,'C29': 0.6,'C30': 0.0,'C31': 0.625,'C32': 1.0,'C33': 0.0,'C34': 0.8333333333333334,'C36': 0.2,'C37': 1.0,'C40': 0.37037037037037035,'C41': 0.43478260869565216,'C42': 0.5471698113207547,'C43': 0.7692307692307693,'C44': 0.4482758620689655,'C45': 0.5434782608695652,'C46': 0.6666666666666666,'C47': 0.49019607843137253,'C48': 0.48,'C49': 0.5714285714285714,'C50': 0.4788732394366197,'C51': 0.0,'C52': 0.6666666666666666,'C53': 0.5423728813559322,'C54': 0.4444444444444444,'C55': 0.6,'C56': 0.5,'C57': 0.6666666666666666,'C58': 0.5,'C59': 0.0,'C60': 0.6875,'C61': 0.5,'C62': 0.3333333333333333,'C63': 0.42857142857142855,'C64': 0.75,'C65': 0.5652173913043478,'C66': 0.5,'C67': 0.43478260869565216,'C68': 0.5,'C69': 0.7142857142857143,'C70': 0.3,'C71': 0.5,'C72': 0.5,'C74': 1.0,'C75': 1.0,'C76': 0.0,'C77': 0.6666666666666666,'C78': 0.3448275862068966,'C80': 0.8,'C82': 0.6666666666666666,'C84': 0.0,'C86': 0.0,'C88': 0.5833333333333334,'C89': 0.0,'C90': 0.5,'C91': 0.3333333333333333,'C92': 0.5,'C94': 0.0,'C95': 0.75,'C97': 0.5,'C99': 1.0,'D00': 0.46621621621621623,'D01': 0.5299145299145299,'D02': 0.5238095238095238,'D03': 0.5454545454545454,'D04': 0.23076923076923078,'D05': 0.7142857142857143,'D06': 0.5555555555555556,'D07': 0.5,'D08': 0.5384615384615384,'D09': 0.0,'D10': 0.46153846153846156,'D11': 0.4827586206896552,'D12': 0.5882352941176471,'D13': 0.5,'D14': 0.7142857142857143,'D15': 0.6511627906976745,'D16': 0.3333333333333333,'D17': 0.625,'D18': 0.0,'D19': 0.42857142857142855,'D20': 0.5,'D21': 0.5454545454545454,'D22': 1.0,'D23': 0.7142857142857143,'D24': 0.2,'D25': 0.7777777777777778,'D26': 0.5555555555555556,'D27': 0.7777777777777778,'D28': 1.0,'D30': 0.5443037974683544,'D31': 0.4520547945205479,'D32': 0.6,'D33': 0.5714285714285714,'D34': 0.5454545454545454,'D35': 0.6101694915254238,'D36': 0.7,'D37': 0.4745762711864407,'D38': 0.47368421052631576,'D39': 1.0,'D40': 0.6666666666666666,'D41': 0.2727272727272727,'D42': 0.5,'D43': 0.6666666666666666,'D44': 0.3333333333333333,'D45': 0.5925925925925926,'D46': 0.8,'D47': 0.375,'D48': 1.0,'D49': 0.0,'D50': 0.6666666666666666,'D52': 0.5,'D53': 0.75,'D55': 0.5833333333333334,'D56': 0.5,'D57': 0.0,'D58': 0.75,'D59': 0.0,'D60': 0.6666666666666666,'D61': 0.6666666666666666,'D66': 1.0,'D70': 0.5,'D74': 0.6666666666666666,'D75': 0.0,'D76': 0.0,'D77': 0.6153846153846154,'D78': 0.5,'D79': 0.5555555555555556,'D80': 0.42857142857142855,'D82': 0.3333333333333333,'D83': 0.0,'D85': 0.4423076923076923,'D86': 0.5,'D87': 0.5,'D88': 0.0,'D89': 1.0,'D90': 0.4166666666666667,'D91': 0.5714285714285714,'D92': 0.0,'D93': 0.0,'D94': 0.3333333333333333,'D95': 1.0,'D96': 1.0,'D97': 0.8,'E00': 0.5,'E01': 0.5625,'E04': 0.5357142857142857,'E05': 1.0,'E06': 0.5471698113207547,'E07': 0.6666666666666666,'E08': 0.3333333333333333,'E09': 0.6666666666666666,'E10': 0.45454545454545453,'E11': 0.4444444444444444,'E12': 0.6521739130434783,'E13': 0.5,'E14': 0.0,'E15': 0.5757575757575758,'E16': 0.6363636363636364,'E17': 0.7142857142857143,'E18': 0.5454545454545454,'E19': 0.5,'E20': 0.45161290322580644,'E21': 0.3333333333333333,'E22': 0.5,'E23': 1.0,'E24': 0.7272727272727273,'E25': 0.5,'E26': 1.0,'E27': 0.7142857142857143,'E28': 0.0,'E29': 1.0,'E30': 0.4444444444444444,'E31': 1.0,'E32': 0.5238095238095238,'E33': 0.4,'E34': 0.25,'E35': 0.0,'E36': 0.25,'E37': 1.0,'E38': 0.38461538461538464,'E39': 0.3333333333333333,'E40': 0.3333333333333333,'E41': 0.6,'E42': 0.5,'E43': 0.0,'E44': 0.0,'E45': 1.0,'E46': 0.9166666666666666,'E47': 0.6,'E48': 0.7692307692307693,'E49': 1.0,'E50': 0.0,'E51': 0.0,'E52': 0.0,'E53': 0.5,'E54': 0.5,'E60': 0.5588235294117647,'E61': 0.6470588235294118,'E62': 0.5925925925925926,'E63': 0.7142857142857143,'E65': 0.2,'E66': 0.25,'E67': 0.75,'E68': 0.6470588235294118,'E69': 0.6666666666666666,'E70': 0.5,'E71': 0.5263157894736842,'E72': 1.0,'E73': 0.35294117647058826,'E74': 0.2,'E75': 0.5,'E76': 0.3333333333333333,'E77': 0.0,'E79': 1.0,'E80': 1.0,'E81': 0.6666666666666666,'E82': 0.0,'E83': 0.6666666666666666,'E84': 1.0,'E85': 0.0,'E87': 0.5,'E90': 0.3888888888888889,'E91': 0.6,'E92': 0.6486486486486487,'E93': 1.0,'E94': 0.4117647058823529,'E95': 0.3333333333333333,'E97': 0.5833333333333334,'E98': 0.5714285714285714,'E99': 0.0}


def transform_data(df):
    
    df.fillna(df.mean(), inplace=True)
    df.fillna(df.mode().iloc[0], inplace=True)
    df['ECO']=df['ECO'].map(ECO_map)
    df = df.drop('MatchID', axis=1)
    df['prob_white_win']=np.ones(df.shape[0])/(np.ones(df.shape[0])+np.power(10, (df['BlackElo']-df['WhiteElo'])/400))
    X=df.filter(['WhiteElo','BlackElo','ECO','eval','prob_white_win'], axis = 1)
    scaler = MinMaxScaler()
    X = scaler.fit_transform(X)
    return X



def generate_model(x):
    '''
    Your logic goes here 
    '''
    train_data = x
    y_train = train_data['Result']
    X_train = transform_data(train_data)
    modelgbm=LGBMClassifier()
    modelgbm.fit(X_train, y_train)
    return modelgbm

def code_driver(train=False):
    train_data = pd.read_csv("train.csv")
    test_data = pd.read_csv("test.csv")
    if train == True:
        model = generate_model(train_data)
        pd.to_pickle(model,'model.pkl')
    else:
        model = pd.read_pickle('model.pkl')
    
    test_data1 = transform_data(test_data) # test_data1 is the transformed test data
    test_results = model.predict_proba(test_data1)
    test_results_df = pd.DataFrame(test_data['MatchID'])
    test_results_df['Prob'] = pd.DataFrame(test_results)[1]
    test_results_df.to_csv("submission.csv", index=False)
 
if __name__ == "__main__":
    code_driver(train=True) 